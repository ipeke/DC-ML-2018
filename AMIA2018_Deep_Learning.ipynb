{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMIA2018-Deep-Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeke/DC-ML-2018/blob/master/AMIA2018_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3ZgsV6QHgsTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation and Interpretability in Deep Learning\n",
        "## AMIA 2018\n",
        "\n",
        "Welcome to the AMIA 2018 tutorial on \"Evaluation and Interpretability in Deep Learning\"!\n",
        "\n",
        "This notebook will guide you through the interactive session. Feel free to work through at your own pace, and let us know if you have any questions."
      ]
    },
    {
      "metadata": {
        "id": "G7it1K33WkYM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First we'll need to set up the Colab environment for our exercises.\n",
        "\n",
        "If you haven't already, click the \"Connect\" button in the top-right corner.\n",
        "\n",
        "Then, run the next code segment to import the packages we'll need. (You might have to accept a prompt.)"
      ]
    },
    {
      "metadata": {
        "id": "7uoWALN-gn51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set up environment\n",
        "\n",
        "# for our DNN model\n",
        "import tensorflow\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# for setting up our data and evaluating results\n",
        "from sklearn.datasets import make_classification, make_blobs, make_moons\n",
        "from sklearn.metrics import precision_recall_fscore_support, \\\n",
        "confusion_matrix, roc_curve, auc, \\\n",
        "precision_recall_curve, average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# visualizations\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ktMdhFkW__P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll be using a straightforward DNN binary classsification model for our demonstrations, and a toy dataset that we can build using the following functions.\n",
        "\n",
        "Run the next code block to define the model building and data generation methods."
      ]
    },
    {
      "metadata": {
        "id": "s0YUGULfgSuf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up our model and a toy dataset to demonstrate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "# Data is going to be from the sklearn make_classification function\n",
        "def get_data(balance=None):\n",
        "  #X, y = make_moons(n_samples=2000,\n",
        "  #                 noise=0.2)\n",
        "  \n",
        "  X, y = make_classification(n_samples=5000,\n",
        "                          n_features=50,\n",
        "                          n_clusters_per_class=2,\n",
        "                          n_informative=50,\n",
        "                          n_redundant=0,\n",
        "                             shuffle=False,\n",
        "                            weights=balance,\n",
        "                            flip_y=0.0)\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "# set up our model\n",
        "\n",
        "\n",
        "def get_model():\n",
        "  '''\n",
        "  Define a small, fully-connected network for demonstration purposes\n",
        "  '''\n",
        "  model = Sequential()\n",
        "  model.add(Dense(25, \n",
        "                  input_dim=X.shape[1], \n",
        "                  kernel_initializer='uniform', \n",
        "                  activation='relu'))\n",
        "  model.add(Dense(2))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  sgd = SGD(lr=0.01)\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "               optimizer=sgd,\n",
        "               metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ysO8GoSbXNTs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Working with Balanced Data\n",
        "\n",
        "We'll be looking at a binary classification problem for these exercises, where our outputs (y) are either 0 or 1. In the first example, we'll look at balanced data, where the number of examples labeled 0 is the same as the number of examples labeled 1.\n",
        "\n",
        "The next code block gets our data and plots a histogram of the y values to confirm that they are in fact balanced."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9P7WMmSXjUpg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, y = get_data()\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(y)\n",
        "plt.show()\n",
        "\n",
        "model = get_model()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLwtQd5LXuPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once we have our data, we split it into training and testing partitions.\n",
        "\n",
        "This way, we can have a held-out test set to validate our model with.\n",
        "\n",
        "In the code below, \"stratify\" ensures that the label balance is maintained in the training and testing partitions (this will be important later).\n",
        "\n",
        "Again, we plot a histogram to look at the distribution of labels in the training and testing set."
      ]
    },
    {
      "metadata": {
        "id": "IU58UZmPkQae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split the data into training and testing \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.5, \n",
        "                                                    stratify=y)\n",
        "print(X_train.size, X_test.size)\n",
        "plt.figure()\n",
        "plt.hist([y_train, y_test], label=['training', 'testing'])\n",
        "plt.legend(loc=0)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-u6EAgC8YH9l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this next block we're going to define a function to handle our model training and evaluation.\n",
        "\n",
        "It's going to do a lot of the heavy lifting for us in our examples.\n",
        "\n",
        "First, we train our model (model.fit) and calculate test-set accuracy (model.evaluate)\n",
        "\n",
        "Since we want to run some more metrics, we also call model.predict to get the outputs of the model so that we can compare them to the true labels."
      ]
    },
    {
      "metadata": {
        "id": "wNzgZ3EclXla",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test, config):\n",
        "  '''\n",
        "  Here we're going to define our model training and evaluation procedure.\n",
        "  We will:\n",
        "  1. train our model with X_train and y_train\n",
        "  2. calculate test metrics with X_test and y_test\n",
        "  3. Plot our Reciever Operating Characteristic and Average Precision Curves\n",
        "  '''\n",
        "  \n",
        "  print('######### Training the model #########')\n",
        "  # convert labels to categorical for model\n",
        "  y_train_cat = np_utils.to_categorical(y_train)\n",
        "  y_test_cat = np_utils.to_categorical(y_test)\n",
        "  model.fit(X_train, y_train_cat, \n",
        "            epochs=config['epochs'], \n",
        "            batch_size=config['batch_size'], \n",
        "            verbose=config['verbose']) \n",
        "  (loss, acc) = model.evaluate(X_train, y_train_cat, batch_size=32, verbose=config['verbose'])\n",
        "  print('Loss: {}, accuracy: {}'.format(loss, acc))\n",
        "  \n",
        "  print('######### Calculating test set accuracy #########')\n",
        "  (loss, acc) = model.evaluate(X_test, y_test_cat, batch_size=32, verbose=config['verbose'])\n",
        "  print('Loss: {}, accuracy: {}'.format(loss, acc))\n",
        "  preds = model.predict(X_test, \n",
        "                        batch_size=config['batch_size'], \n",
        "                        verbose=config['verbose'])\n",
        "  predictions = np.argmax(preds, axis=1)\n",
        "  \n",
        "  print('######### Test set confusion matrix #########')\n",
        "  print(confusion_matrix(y_test, predictions))\n",
        "\n",
        "  print('######### Precision, recall, and F1 scores #########')\n",
        "  print(precision_recall_fscore_support(y_test, predictions))\n",
        "\n",
        "  print('######### Plotting ROC #########')\n",
        "  # here we can use the p(y=1) values \n",
        "  fpr, tpr, _ = roc_curve(y_test, preds[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  plt.figure()\n",
        "  lw = 2\n",
        "  plt.plot(fpr, tpr, color='darkorange',\n",
        "           lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver operating characteristic example')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "  \n",
        "  print('######### Plotting precision-recall curve #########')\n",
        "  average_precision = average_precision_score(y_test, preds[:, 1])\n",
        "  precision, recall, _ = precision_recall_curve(y_test, preds[:, 1])\n",
        "\n",
        "  plt.step(recall, precision, color='b', alpha=0.2,\n",
        "           where='post')\n",
        "  plt.fill_between(recall, precision, alpha=0.2, color='b', step='post')\n",
        "\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "            average_precision))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEYSuQDMzmvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have our functions defined, let's train our model on the data we have.\n",
        "\n",
        "The config dictionary handles some of the hyperparameters for model training. Feel free to change the batch size and number of epochs for training.\n",
        "\n",
        "Also, if you change 'verbose' to 1, you'll see per-epoch outputs. This is nice when you want to see how quickly the model training improves.\n"
      ]
    },
    {
      "metadata": {
        "id": "JICZE2plzqrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'epochs': 50,\n",
        "    'batch_size': 128,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "train_and_evaluate(model, X_train, y_train, \n",
        "                   X_test, y_test, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06SrhoHiz9vw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imbalanced Data\n",
        "\n",
        "In the last section we saw how the model generalizes when dealing with balanced data.\n",
        "\n",
        "What about imbalanced data? For example, you may want to train a model that detects some rare adverse event in text. It's important to set up your learning problem in such a way that you are prepared for imbalanced data if that is what you expect to see.\n",
        "\n",
        "First, we'll train a model with imbalanced data with a random training-testing split and look at what happens."
      ]
    },
    {
      "metadata": {
        "id": "ZvW_HgEKY4qW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# let's look at imbalanced data where we don't stratify\n",
        "X, y = get_data(balance=[0.9, 0.1])\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(y)\n",
        "plt.show()\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "X_train = np.vstack((X[:4000], X[4900:]))\n",
        "X_test = X[4000:4900]\n",
        "\n",
        "y_train = np.hstack((y[:4000],y[4900:]))\n",
        "y_test = y[4000:4900]\n",
        "\n",
        "# split the data into training and testing \n",
        "#X_train, X_test, y_train, y_test = \\\n",
        "#      train_test_split(X, y, test_size=0.5, \n",
        "#                       shuffle=True,\n",
        "#                       stratify=None,\n",
        "#                      random_state=42)\n",
        "\n",
        "print(X_train.size, X_test.size)\n",
        "plt.figure()\n",
        "plt.hist([y_train, y_test], label=['training', 'testing'])\n",
        "plt.legend(loc=0)\n",
        "plt.show()\n",
        "\n",
        "config = {\n",
        "    'epochs': 50,\n",
        "    'batch_size': 128,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "train_and_evaluate(model, X_train, y_train, \n",
        "                   X_test, y_test, config)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HLPHAIeq1uh_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Take a look at the confusion matrix, particularly for the positive examples. The poor performance there pulls down the F1 score, even though accuracy is still high.\n",
        "\n",
        "In the next block, we'll \"stratify\" our training and testing split so that the distribution over the labels is consistent between training and testing.\n",
        "\n",
        "We'll use the same dataset as the last example so we can directly compare the difference."
      ]
    },
    {
      "metadata": {
        "id": "Fb-zZ4azeJfN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize new model\n",
        "model = get_model()\n",
        "\n",
        "# split the data into training and testing \n",
        "# note the stratify arg here\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "      train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True)\n",
        "\n",
        "print(X_train.size, X_test.size)\n",
        "plt.figure()\n",
        "plt.hist([y_train, y_test], label=['training', 'testing'])\n",
        "plt.legend(loc=0)\n",
        "plt.show()\n",
        "\n",
        "config = {\n",
        "    'epochs': 50,\n",
        "    'batch_size': 128,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "train_and_evaluate(model, X_train, y_train, \n",
        "                   X_test, y_test, config)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iERNlLizFvZ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because the data is balanced, there are fewer misclassified positive examples, and F1 score for those positive examples is higher.\n",
        "\n",
        "## Wrapping Up\n",
        "\n",
        "Feel free to experiment with this code! You can change the model, how the data is generated, etc.\n",
        "\n",
        "Once you are finished, you can save your copy of the notebook to your Google Drive account by clicking \"File\" --> \"Save a copy in Drive\""
      ]
    }
  ]
}